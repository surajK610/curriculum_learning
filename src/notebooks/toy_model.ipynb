{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cf1d0e9-e2e6-413c-a063-60571c0ee75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a19c35b4-6674-4c86-b458-f69f9fedef5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pythia = AutoModel.from_pretrained('EleutherAI/pythia-160m')\n",
    "bert = AutoModel.from_pretrained('google/multiberts-seed_0-step_0k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0c75654-a00d-42d5-af7d-55805cb3721c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/sanand14/.local/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /oscar/home/sanand14/.local/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN3c104cuda20CUDACachingAllocator12recordStreamERKNS_7DataPtrENS0_10CUDAStreamE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import logging\n",
    "from typing import cast, Dict, List, Tuple, Union\n",
    "from typing_extensions import get_args, Literal\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import random \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import yaml\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from functools import partial\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformer_lens.utils import is_square\n",
    "from transformer_lens.head_detector import (compute_head_attention_similarity_score, \n",
    "                      get_previous_token_head_detection_pattern, \n",
    "                      get_duplicate_token_head_detection_pattern,\n",
    "                      get_induction_head_detection_pattern)\n",
    "\n",
    "\n",
    "\n",
    "sys.path.append('/users/sanand14/data/sanand14/learning_dynamics/src/experiments/utils')\n",
    "sys.path.append('/users/sanand14/data/sanand14/learning_dynamics/src/experiments')\n",
    "\n",
    "from aheads import create_repeats_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd9d88d-c619-4277-94d8-e306f1a05080",
   "metadata": {},
   "source": [
    "## TOY MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7d2a3ba7-174f-4ae6-a706-161b4406297e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyModel(nn.Module):\n",
    "    def __init__(self, num_features: int, num_interm : int):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(num_features, num_interm)\n",
    "        # Second fully connected layer\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(num_interm, num_interm)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.head = nn.Linear(num_interm, 1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if isinstance(x, list):\n",
    "            x, _ = x\n",
    "        emb = self.relu1(self.fc1(x))\n",
    "        out = self.relu2(self.fc2(emb))# + emb\n",
    "        return self.head(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56579a94-10cd-4d1f-b93b-9f90b85bb9b3",
   "metadata": {},
   "source": [
    "* Train on disambiguated data to detect mean m1\n",
    "* Train on ambiguated data to detect whole task\n",
    "* Check whether inetermediate layer data is split by mean m1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53127c89-eb47-40f0-aef8-e7058934060c",
   "metadata": {},
   "source": [
    "#### Make Deterministic Plz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "25fa7cf6-026c-438b-9459-c598e3452ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27eb1e06-95b3-4394-9863-f5e73b9acfe6",
   "metadata": {},
   "source": [
    "### Gen Data Func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4dafcdc3-a1d9-453f-a4fa-6602fd5fd598",
   "metadata": {},
   "outputs": [],
   "source": [
    "## generation hyperparameters\n",
    "\n",
    "size = 10000\n",
    "m1, m2, m3, m4 = 0, 0, 2, 3\n",
    "s1, s2, s3, s4 = 1, 1, 1, 1 ## dec to 0.2\n",
    "N, N_p, N_pp = 0, 2, 3\n",
    "vec_size = 16 ## was 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "595b5ff2-4935-40f5-93b5-e552051a28d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gaussian_inputs(m1, s1, m2, s2, m3, s3, m4, s4, vec_size, N, N_p, N_pp, init_task=True, disamb=0.5):\n",
    "    f1 = torch.normal(mean=torch.tensor(m1).repeat((1, vec_size)).float(), std=s1)\n",
    "    f2 = torch.normal(mean=torch.tensor(m2).repeat((1, vec_size)).float(), std=s2)\n",
    "    f3 = torch.normal(mean=torch.tensor(m3).repeat((1, vec_size)).float(), std=s3)\n",
    "    f4 = torch.normal(mean=torch.tensor(m4).repeat((1, vec_size)).float(), std=s4)\n",
    "    f1_gt_N = (torch.mean(f1) > N)\n",
    "    f2_gt_N = (torch.mean(f2) > N)\n",
    "    if random.random() < disamb: ## f1 > N != f2 > N (i.e. ambiguous)\n",
    "        while f1_gt_N == f2_gt_N:\n",
    "            f1 = torch.normal(mean=torch.tensor(m1).repeat((1, vec_size)).float(), std=s1)\n",
    "            f2 = torch.normal(mean=torch.tensor(m2).repeat((1, vec_size)).float(), std=s2)\n",
    "            f1_gt_N = (torch.mean(f1) > N)\n",
    "            f2_gt_N = (torch.mean(f2) > N)\n",
    "    else: ## f1 > N == f2 > N (i.e. ambiguous)\n",
    "        while f1_gt_N != f2_gt_N:\n",
    "            f1 = torch.normal(mean=torch.tensor(m1).repeat((1, vec_size)).float(), std=s1)\n",
    "            f2 = torch.normal(mean=torch.tensor(m2).repeat((1, vec_size)).float(), std=s2)\n",
    "            f1_gt_N = (torch.mean(f1) > N)\n",
    "            f2_gt_N = (torch.mean(f2) > N)\n",
    "            \n",
    "    full = torch.concat([f1, f2, f3, f4], dim=1) \n",
    "    if init_task:\n",
    "        label = f1_gt_N\n",
    "        alt_label = f2_gt_N\n",
    "    else:\n",
    "        label = (torch.mean(f3) > N_p) if f1_gt_N else (torch.mean(f4) > N_pp)\n",
    "        alt_label = (torch.mean(f3) > N_p) if f2_gt_N else (torch.mean(f4) > N_pp) \n",
    "    return full, label, alt_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a0d5f5d9-5ca3-4935-991d-3af02c013c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(init_task, disamb):\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    alt_labels = []\n",
    "    \n",
    "    for i in (range(size)):\n",
    "        input, label, alt_label = generate_gaussian_inputs(m1, s1, m2, s2, m3, s3, m4, s4, vec_size, N, N_p, N_pp, init_task=init_task, disamb=disamb)\n",
    "        inputs.append(input)\n",
    "        labels.append(label)\n",
    "        alt_labels.append(alt_label)\n",
    "        \n",
    "    inputs = torch.vstack(inputs)\n",
    "    labels = torch.vstack(labels).float()\n",
    "    alt_labels = torch.vstack(alt_labels).float()\n",
    "    \n",
    "    train_size = int(0.8 * len(inputs))\n",
    "    \n",
    "    inputs_t, labels_t, alt_labels_t = inputs[:train_size], labels[:train_size], alt_labels[:train_size]\n",
    "    inputs_v, labels_v, alt_labels_v = inputs[train_size:], labels[train_size:], alt_labels[train_size:]\n",
    "\n",
    "    train_dataset = TensorDataset(inputs_t.detach(), labels_t.view(-1, 1))\n",
    "    val_dataset = TensorDataset(inputs_v.detach(), labels_v.view(-1, 1))\n",
    "\n",
    "    train_dataset_alt = TensorDataset(inputs_t.detach(), alt_labels_t.view(-1, 1))\n",
    "    val_dataset_alt = TensorDataset(inputs_v.detach(), alt_labels_v.view(-1, 1))\n",
    "\n",
    "    return train_dataset, val_dataset, train_dataset_alt, val_dataset_alt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097ab96f-f20d-40e0-98bb-da3380e96f3b",
   "metadata": {},
   "source": [
    "### Model Params/Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "812b82c6-b881-4feb-b629-351a306870fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## model params/hyperparams\n",
    "\n",
    "epochs = 2\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "interm_size = 256 ## was 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cf2ed89f-46b4-469f-9635-f0fdc6557656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(model, batch):\n",
    "    x, y = batch\n",
    "    logits = model.forward(x)\n",
    "    loss = F.binary_cross_entropy(torch.sigmoid(logits), y)\n",
    "    acc = ((logits.squeeze() > 0.5).float() == y.squeeze()).float().mean()\n",
    "    return loss, {\"loss\": loss.item(), \"acc\": acc.item()}\n",
    "\n",
    "def train_loop(model, train_dataloader, test_dataloader, optimizer, epochs):\n",
    "    pbar = tqdm(range(epochs))\n",
    "    for epoch in pbar:\n",
    "        pbar.set_description(f\"Training Epoch {epoch}\")\n",
    "        for batch in train_dataloader:\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            loss, stats = step(model, batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pbar.set_postfix(**stats)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            pbar.set_description(\"Validation\")\n",
    "            for val_batch in test_dataloader:\n",
    "                loss, stats = step(model, val_batch)\n",
    "                pbar.set_postfix(**stats)\n",
    "                \n",
    "def val_loop(model, test_dataloader):\n",
    "    model.eval()\n",
    "    acc, losses = [], []\n",
    "    with torch.no_grad():\n",
    "        for val_batch in tqdm(test_dataloader):\n",
    "            loss, stats = step(model, val_batch)\n",
    "            acc.append(stats[\"acc\"])\n",
    "            losses.append(stats[\"loss\"])\n",
    "    return np.mean(acc), np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0b93d919-a982-4109-a285-e7a7ab8e0379",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_model = ToyModel(4*vec_size, interm_size)\n",
    "optimizer = torch.optim.Adam(toy_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23496a6-8f71-41cc-976b-b7ecade0abf9",
   "metadata": {},
   "source": [
    "### Task 1: Learn mean(f1) > N on disambiguated data \n",
    "\n",
    "disambiguated = where mean(f2) > N is the same label with p=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e1845b8b-2db9-4ba9-871a-367cdc3cf928",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b825c8c215d4a9fa60cbe3666b2b1fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee1017151f454d45b47ff7278e7f4813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY: 0.97, LOSS: 0.09\n"
     ]
    }
   ],
   "source": [
    "def task1(toy_model, optimizer, epochs):\n",
    "    train_dataset, val_dataset, _, _ = create_dataset(init_task=True, disamb=0.5)\n",
    "    \n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "    train_loop(toy_model, train_dataloader, val_dataloader, optimizer, epochs)\n",
    "    acc, loss = val_loop(toy_model, val_dataloader)\n",
    "    print(f\"ACCURACY: {acc:0.2f}, LOSS: {loss:0.2f}\")\n",
    "    \n",
    "task1(toy_model, optimizer, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147e0c8d-c78b-4fd3-8c4f-7d8e07bada8a",
   "metadata": {},
   "source": [
    "### Task 2: Learn mean(f3) > N' if mean(f1) > N else mean(f4) > N'' on ambiguated data \n",
    "\n",
    "ambiguated = where mean(f2) > N is the same label with p=0.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "696c857b-185f-469a-be61-7efd98946823",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_model_new = ToyModel(4*vec_size, interm_size) ## ab 75-80% baseline\n",
    "optimizer_new = torch.optim.Adam(toy_model_new.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f742d8e9-e0d3-46c5-9ab3-874869681a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1490ca0f2384cc491399cc8a5d00904",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def task2(toy_model, optimizer, epochs):\n",
    "    train_dataset, val_dataset, _, _ = create_dataset(init_task=False, disamb=0.00)\n",
    "    \n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "    train_loop(toy_model, train_dataloader, val_dataloader, optimizer, epochs)\n",
    "    acc, loss = val_loop(toy_model, val_dataloader)\n",
    "    print(f\"ACCURACY: {acc:0.2f}, LOSS: {loss:0.2f}\")\n",
    "\n",
    "task2(toy_model, optimizer, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2984d86-b49c-4fe1-84af-e0cbdfd14b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "task2(toy_model_new, optimizer_new, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5af737-88c2-4a05-85b5-9516f2b7cddb",
   "metadata": {},
   "source": [
    "### Check: whether intermediate data is better at mean(f1) > N or mean(f2) > N on disambiguated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be982669-1226-45e3-a48d-1bc8cf4a7f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, alt_train_dataset, alt_val_dataset = create_dataset(init_task=False, disamb=1)\n",
    "\n",
    "label_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "alt_label_dataloader = DataLoader(alt_val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37436796-13b4-40a4-aac9-ed646212ed22",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, loss = val_loop(toy_model, label_dataloader)\n",
    "print(f\"F1 LABELS ACCURACY: {acc:0.2f}, LOSS: {loss:0.2f}\")\n",
    "acc, loss = val_loop(toy_model, alt_label_dataloader)\n",
    "print(f\"F2 LABELS ACCURACY: {acc:0.2f}, LOSS: {loss:0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89979c64-2688-4f4a-95c4-763d700071e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, loss = val_loop(toy_model_new, label_dataloader)\n",
    "print(f\"F1 LABELS ACCURACY: {acc:0.2f}, LOSS: {loss:0.2f}\")\n",
    "acc, loss = val_loop(toy_model_new, alt_label_dataloader)\n",
    "print(f\"F2 LABELS ACCURACY: {acc:0.2f}, LOSS: {loss:0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe393f4a-1a9c-4f9a-abcd-3a25d15f8725",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1_biased = toy_model.fc1\n",
    "layer1_control = toy_model_new.fc1\n",
    "\n",
    "train_dataset, val_dataset, alt_train_dataset, alt_val_dataset = create_dataset(init_task=True, disamb=0.5)\n",
    "## need to be ambiguous be maximally random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb36c7c5-a685-4ffa-b293-26e5af41dbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_pcas(interm_train, labels_train, alt_labels_train, title=\"biased\"):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    \n",
    "    disamb_learn_numpy = interm_train.detach().numpy()\n",
    "    pca = PCA(n_components=2)\n",
    "    data_pca = pca.fit_transform(disamb_learn_numpy)\n",
    "    \n",
    "    for i, labels_curr in enumerate([labels_train, alt_labels_train]):\n",
    "        labels_numpy = labels_curr.squeeze()\n",
    "        unique_labels = np.unique(labels_numpy)\n",
    "        colors = plt.cm.get_cmap('viridis', len(unique_labels))\n",
    "        \n",
    "        for j, label in enumerate(unique_labels):\n",
    "            axs[i].scatter(data_pca[labels_numpy == label, 0], data_pca[labels_numpy == label, 1], \n",
    "                        alpha=0.5, color=colors(j), label=f\"Label {label}\")\n",
    "        \n",
    "        axs[i].set_title(f\"Separation of mean(f{i+1}) > N\")\n",
    "        axs[i].set_xlabel(\"Principal Component 1\")\n",
    "        axs[i].set_ylabel(\"Principal Component 2\")\n",
    "        axs[i].legend()\n",
    "        axs[i].grid(True)\n",
    "\n",
    "    plt.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "interm_train_biased, interm_val_biased = layer1_biased(train_dataset.tensors[0]), layer1_biased(val_dataset.tensors[0])\n",
    "labels_train, labels_val = train_dataset.tensors[1], val_dataset.tensors[1]\n",
    "alt_labels_train, alt_labels_val = alt_train_dataset.tensors[1], alt_val_dataset.tensors[1]\n",
    "\n",
    "plot_pcas(interm_train_biased, labels_train, alt_labels_train, title=\"Pretrained\")\n",
    "\n",
    "interm_train_control, interm_val = layer1_control(train_dataset.tensors[0]), layer1_control(val_dataset.tensors[0])\n",
    "\n",
    "plot_pcas(interm_train_control, labels_train, alt_labels_train, title=\"Not Pretrained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd5880f-227d-4597-92f9-67331b65b301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "scipy.stats.pearsonr(labels_train.squeeze(), alt_labels_train.squeeze()) \n",
    "## uncorrelated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9223b1af-1903-4080-b2bf-04b6400a0887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 128)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disamb_learn_numpy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "034b33d6-4cb2-4107-a0e4-d3ea0c289b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8000, 1])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a30d8ce9-b2ba-4b8e-88ac-227940998bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Corr Label 0.5988681562903855 , Max Corr Alt Label 0.5482244454480574\n",
      "\n",
      "Top 10 Corr Label [0.59886816 0.55941821 0.55115218 0.54402599 0.5433952  0.52871933\n",
      " 0.52069526 0.51768924 0.48808707 0.46045053] \n",
      "Top 10 Corr Alt Label [0.54822445 0.47418461 0.46007081 0.43732092 0.42496988 0.41557385\n",
      " 0.40782031 0.40142805 0.39683998 0.39470528]\n"
     ]
    }
   ],
   "source": [
    "corr_label_dims = [scipy.stats.pearsonr(labels_train.squeeze(), interm_train.detach()[:, i]).statistic for i in range(interm_train.shape[1])]\n",
    "corr_alt_label_dims = [scipy.stats.pearsonr(alt_labels_train.squeeze(), interm_train.detach()[:, i]).statistic for i in range(interm_train.shape[1])]\n",
    "\n",
    "plt.hist(corr_label_dims, alpha=0.5, label='List 1')\n",
    "plt.hist(corr_alt_label_dims, alpha=0.5, label='List 2')\n",
    "plt.title('Histogram of Correlation of Dimensions')\n",
    "plt.xlabel('Corr')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(['Label', 'Alt Label'])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print('Max Corr Label', max(corr_label_dims), ', Max Corr Alt Label', max(corr_alt_label_dims))\n",
    "print('\\nTop 10 Corr Label', torch.topk(torch.tensor(corr_label_dims), 10).values.numpy(), '\\nTop 10 Corr Alt Label', torch.topk(torch.tensor(corr_alt_label_dims), 10).values.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a08bcc-ea79-4ed2-b752-865085c2e283",
   "metadata": {},
   "source": [
    "Have some higher frequency of correlation, which is important/shows some difference potentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d5383fc0-fa76-4767-ad51-f1e5b0ee58f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Probe(pl.LightningModule):\n",
    "    def __init__(self, num_features: int):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        self.body = nn.Linear(num_features, 1, bias=False)\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=1e-2)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, logs = self.step(batch)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"train_acc\", logs[\"acc\"], on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return {\"loss\": loss, \"train_loss\": logs[\"acc\"]}\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, logs = self.step(batch)\n",
    "        self.log(\"val_loss\", loss.item(), on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"val_acc\", logs[\"acc\"], on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return {\"loss\": loss, \"val_acc\": logs[\"acc\"]}\n",
    "    \n",
    "    def step(self, batch):\n",
    "        x, y = batch\n",
    "        logits = self.forward(x)\n",
    "        loss = F.binary_cross_entropy(torch.sigmoid(logits), y)\n",
    "        acc = ((logits.squeeze() > 0.5).float() == y.squeeze()).float().mean()\n",
    "        return loss, {\"loss\": loss.item(), \"acc\": acc.item()}\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if isinstance(x, list):\n",
    "            x, _ = x\n",
    "        return self.body(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "cbed86ea-9d19-4d4b-b57a-2c9aeac8cf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(interm_train))\n",
    "\n",
    "train_dataset = TensorDataset(interm_train.detach(), labels_train.view(-1, 1))\n",
    "val_dataset = TensorDataset(interm_val.detach(), labels_val.view(-1, 1))\n",
    "\n",
    "train_dataset_alt = TensorDataset(interm_train.detach(), alt_labels_train.view(-1, 1))\n",
    "val_dataset_alt = TensorDataset(interm_val.detach(), alt_labels_val.view(-1, 1))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "train_dataloader_alt = DataLoader(train_dataset_alt, batch_size=32, shuffle=True)\n",
    "val_dataloader_alt = DataLoader(val_dataset_alt, batch_size=32, shuffle=False)\n",
    "\n",
    "probe_labels = Probe(interm_train.shape[1]).to(device)\n",
    "probe_alt_labels = Probe(interm_train.shape[1]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "32eb35d7-d4d9-4ef3-8d0c-d61a026c0251",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name | Type   | Params\n",
      "--------------------------------\n",
      "0 | body | Linear | 128   \n",
      "--------------------------------\n",
      "128       Trainable params\n",
      "0         Non-trainable params\n",
      "128       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c1b2c3a6d22431db4113cd15bec16f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f512b5be3b34723bdcb7a57b6e75714",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val_acc_epoch       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9664999842643738     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      val_loss_epoch       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05521305650472641    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val_acc_epoch      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9664999842643738    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     val_loss_epoch      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05521305650472641   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss_epoch': 0.05521305650472641, 'val_acc_epoch': 0.9664999842643738}]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(max_epochs=epochs)\n",
    "trainer.fit(probe_labels, train_dataloader, val_dataloader)\n",
    "trainer.validate(probe_labels, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e1753613-0956-4dfc-875e-1aa986f4425b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name | Type   | Params\n",
      "--------------------------------\n",
      "0 | body | Linear | 128   \n",
      "--------------------------------\n",
      "128       Trainable params\n",
      "0         Non-trainable params\n",
      "128       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf1b8135b2c0413d84e9cd15b63ef289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc379eeb3eed439b9ed4abdc35fc7643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val_acc_epoch       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9564999938011169     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      val_loss_epoch       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0874154269695282     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val_acc_epoch      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9564999938011169    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     val_loss_epoch      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0874154269695282    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss_epoch': 0.0874154269695282, 'val_acc_epoch': 0.9564999938011169}]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(max_epochs=1)\n",
    "trainer.fit(probe_alt_labels, train_dataloader_alt, val_dataloader_alt)\n",
    "trainer.validate(probe_alt_labels, val_dataloader_alt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f46951-c624-4a83-ac2a-03e48bf810be",
   "metadata": {},
   "source": [
    "## TRANSPLANTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cade8b7-74df-4c5e-ada9-469b4f5c8b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PYTHIA_VOCAB_SIZE = 50277 #50304\n",
    "N_LAYERS=12\n",
    "MODEL = \"EleutherAI/pythia-160m\"\n",
    "PYTHIA_CHECKPOINTS_OLD = [0, 1, 2, 4, 8, 16, 32, 64, 128, 256, 512] + list(range(1000, 143000 + 1, 10000)) + [143000]\n",
    "PYTHIA_CHECKPOINTS = [512] + list(range(1000, 10000 + 1, 1000))\n",
    "\n",
    "HeadName = Literal[\"previous_token_head\", \"duplicate_token_head\", \"induction_head\"]\n",
    "HEAD_NAMES = cast(List[HeadName], get_args(HeadName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a3f3d7-1203-4760-b3b8-594a801479cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_repeats_dataset(num_samples=50, min_vector_size=5, max_vector_size=50, min_num_repeats=5, max_num_repeats=20, max_vocab=PYTHIA_VOCAB_SIZE):\n",
    "  \"\"\"Creates a dataset for the experiment.\"\"\"\n",
    "  dataset = []\n",
    "  for _ in range(num_samples):\n",
    "    vector_size = torch.randint(min_vector_size, max_vector_size, (1,)).item()\n",
    "    num_repeats = torch.randint(min_num_repeats, max_num_repeats, (1,)).item()\n",
    "    tokens = torch.randint(0, max_vocab, (1, vector_size))\n",
    "    tokens = tokens.repeat((1, num_repeats))\n",
    "    dataset.append(tokens)\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed88b97-5755-4cb5-9252-bcd1f95c5c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.load('../outputs/aheads/dataset.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fa1061d-1a82-4180-975d-304e701a3996",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b8aaa62-84a9-4c7f-8611-a966b7c29a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_attention_head(model1, model2, layer_idx, head_idx, dataset):\n",
    "  if model1.isinstance(HookedTransformer) and model2.isinstance(HookedTransformer):\n",
    "    model1.W_K.data[layer_idx, head_idx, :, :] = model2.W_K.data[layer_idx, head_idx, :, :]\n",
    "    model1.W_Q.data[layer_idx, head_idx, :, :] = model2.W_Q.data[layer_idx, head_idx, :, :]\n",
    "    model1.W_V.data[layer_idx, head_idx, :, :] = model2.W_V.data[layer_idx, head_idx, :, :]\n",
    "    model1.b_K.data[layer_idx, head_idx, :] = model2.b_K.data[layer_idx, head_idx, :]\n",
    "    model1.b_Q.data[layer_idx, head_idx, :] = model2.b_Q.data[layer_idx, head_idx, :]\n",
    "    model1.b_V.data[layer_idx, head_idx, :] = model2.b_V.data[layer_idx, head_idx, :]\n",
    "  else:\n",
    "    model1.encoder.layers[layer_idx].self_attn.in_proj_weight.data[head_idx,:,:] = model2.encoder.layers[layer_idx].self_attn.in_proj_weight.data[head_idx,:,:]\n",
    "  return perplexity(model1, dataset), perplexity(model2, dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a891be09-fbcc-4487-aa72-42fdcfb25203",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity(corpus, model, device=\"cpu\"):\n",
    "    encoded_input = model.to_tokens(corpus)\n",
    "    encoded_input = encoded_input.to(device)\n",
    "    with torch.no_grad():\n",
    "      outputs = model(encoded_input).squeeze(0)\n",
    "      loss = F.cross_entropy(outputs, encoded_input.squeeze(0), reduction='sum')/encoded_input.shape[1]\n",
    "    perplexity = torch.exp(loss).item()\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbe7c40a-eb0a-45a2-a8f6-86b2a581175b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(model, dataset):\n",
    "  data_loader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=False)\n",
    "  with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "      inputs, targets = batch\n",
    "      outputs = model(inputs)\n",
    "      loss = F.cross_entropy(outputs, targets, reduction='sum')\n",
    "      total_loss += loss.item()\n",
    "    average_loss = total_loss / len(data_loader.dataset)\n",
    "    return torch.exp(torch.tensor(average_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b33722-f007-48c9-bbfd-0a231387a349",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
